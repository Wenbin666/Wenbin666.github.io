---
title: Linux开发常见面试题（2）
date: 2020-11-16 15:54:31
tags: interview
categories: 
 - job
---

### 1.内核函数mmap的实现原理，机制?
函数原型：
```C
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
```
功能：内核函数mmap的实现原理与机制主要涉及将文件或其他对象映射到进程的地址空间，从而实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。
addr：映射区起始地址，通常设为NULL，由系统指定。
length：将文件的多大长度映射到内存。
prot：映射区的保护方式，如PROT_READ（可读）、PROT_WRITE（可写）等。
flags：映射区的特性，如MAP_SHARED（共享映射）、MAP_PRIVATE（私有映射）等。
fd：由open返回的文件描述符，代表要映射的文件。
offset：以文件开始处的偏移量，必须是分页大小的整数倍，通常为0。

文件映射概念：
1）给用户提供了一种机制，使得用户可以将文件映射到自己地址空间的某个部分，使用简单的内存访问指令来读写文件。
2）文件映射也可以用于内核的基本组织模式，在这种模式下，内核将整个地址空间视为诸如文件之类的一组不同对象的映射。

内存映射的优势：
1）相比传统的文件访问方式（如使用read、write等系统调用），mmap能够减少系统调用的次数，提高文件访问效率。
2）mmap还可以实现同一文件在多个进程间的共享，节省内存空间。

总结：
1. mmap函数实现把一个文件映射到一个内存区域，从而可以像读写内存一样读写文件，比单纯调用read和hwrite要快。
2. 可以把内存的内容拷贝到一个文件中实现内存备份，当然，也可以把文件的内容映射到内存来恢复某些服务。
3. mmap实现共享内存也是其主要应用之一，mmap系统调用使得进程之间通过映射同一个普通文件实现共享内存。

### 2.驱动里面为什么要有并发、互斥的控制? 如何实现? 讲个例子?
1. 引入并发和互斥控制的原因是为了解决多个执行单元（如多个线程、进程或中断处理程序）同时访问共享资源时可能导致的竞态问题。
2. 竞态问题发生时，不同的执行单元可能会以不可预测的顺序访问共享资源，导致数据不一致、系统状态混乱甚至崩溃。

如何实现并发、互斥的控制：
中断屏蔽、原子操作、自旋锁、信号量、互斥锁等

### 3.说明下vmlinux、zImage和uImage的趋避与联系？
1. vmlinux
vmlinux是Linux内核编译后生成的原始、未压缩且不可直接引导的内核映像文件。它是一个ELF（Executable and Linkable Format）格式的文件，包含了完整的内核代码、调试符号等。

特点：
* 未压缩，因此文件体积相对较大。
* 包含完整的内核代码和调试信息，适合用于内核开发和调试。
* 不可直接用于系统引导，需要进一步处理才能成为可引导的内核映像。

2. zImage
zImage是vmlinux经过gzip压缩后的内核映像文件，同时包含了自解压代码，因此可以直接被引导程序（如GRUB）加载并执行。

特点：
* 压缩后的文件体积显著减小，适合用于嵌入式系统或内存受限的环境。
* 包含了自解压代码，可以在引导过程中自动解压并加载内核。
* 通常适用于内核较小的情况，因为它将内核解压到低端内存（如第一个640KB）。

3. uImage
uImage是专门为U-Boot引导加载程序设计的内核映像文件。它是在zImage的基础上，添加了一个长度为64字节的头部信息，该头部包含了内核的版本、加载位置、生成时间、大小等关键信息。

特点：
* 包含了U-Boot能够识别的头部信息，使得U-Boot能够直接加载并执行内核。
* 头部信息之后的内容与zImage完全相同，即都是从0x40（或类似位置）开始的内容是压缩的内核映像。
* 适用于需要通过U-Boot引导的系统，特别是在嵌入式开发和定制设备中非常常见。

### 4.copy_to_user()和copy_from_user()主要用于实现什么功能? 一般用于file_operations结构的哪些函数?
内核空间和用户空间是不能直接访问的，如果需要访问就必须借助内核函数进行数据读写。
copy_to_user:完成内核空间到用户空间的复制
copy_from_user: 是完成用户空间到内核空间的复制。
一般用于fle_operations结构里的read,write和ioct等内存数据交换作用的函数。当然，如果ioctl没有用到内存数据复制，那么就不会用到这两个函数。

### 5.请简述主设备号和次设备号的用途。如果执行mknod chartest c 4 64创建设备。分析创建的是哪一类设备驱动程序
主设备号:主设备号标识设备对应的驱动程序。虽然现代的linux内核允许多个驱动程序共享主设备号。
次设备号:次设备号由内核使用，用于正确确定设备文件所指的设备。可以通过次设备号获得一个指向内核设备的直接指针。
根据命令中的“c”知道创建的是字符设备，如果是b则为块设备

### 6.emmc测试方式有哪些？
主要是两种：基本读写测试和性能测试
1. 基本读写：
可以通过dd命令：
```bash
dd if=/dev/zero of=/tmp/output bs=1M count=1024 conv=fdatasync,notrunc
```
这条命令测试了向/tmp/output文件写入1GB数据，其中bs=1M指定了块大小为1MB，count=1024指定了块的数量，conv=fdatasync,notrunc参数用于确保数据被写入磁盘并同步。
2. 性能测试：
IOzone是一个文件系统性能测试工具，用于测量不同操作系统下文件系统的读写性能。
用法：通过指定不同的测试参数（如文件大小、记录大小、测试模式等），IOzone可以生成多种测试场景，全面评估EMMC的性能。
特点：支持多种测试模式，如随机读写、顺序读写、混合读写等，可以生成详细的性能报告
命令示例：
```bash
iozone -a -s 1G -r 4k -i 0 -i 1 -i 5 -f /mnt/testdir/testfile
```

### 7.说明什么是孤儿进程，什么是僵尸进程？
1. 孤儿进程（Orphan Process）
当一个父进程在其子进程之前结束运行，而该子进程仍在运行时，这个子进程就称为孤儿进程。
每个进程都必须有一个父进程，因此系统会将孤儿进程的父进程ID（PID）更改为1，即init进程（也称为systemd或其他系统初始化进程）。init进程会负责收养所有孤儿进程，并在它们结束时回收其资源。孤儿进程本身对系统并无直接危害，只是它的父进程发生了变化。

2. 僵尸进程（Zombie Process）
已经结束执行（即已调用exit，系统还没有回收其进程描述符），但其进程描述符（process descriptor）仍然保留在系统中的进程。
通常发生在父进程还没有通过调用wait()或waitpid()等系统调用来读取子进程的终止状态的情况下。由于系统无法释放僵尸进程所占用的进程描述符等资源，这些资源将一直保留到父进程读取了子进程的退出状态为止。因此，如果系统中存在大量的僵尸进程，可能会导致系统资源耗尽，影响系统的正常运行。

### 8.cache有哪些优点？
1. 提高数据访问速度：Cache 是位于CPU和主存RAM之间的高速存储器，其存取速度远快于主存。当CPU需要访问数据时，会首先检查 Cache中是否已有该数据的副本（即缓存命中）。如果命中，CPU 可以直接从 Cache 中读取数据，而无需等待较慢的主存访问，从而显著提高数据访问速度。
2. 减少主存访问次数：通过频繁地使用 Cache 存储最近访问的数据和指令，可以显著减少 CPU 直接访问主存的次数。主存的访问速度较慢，且访问成本（如功耗、延迟）较高。因此，减少主存访问次数有助于提升系统的整体性能和效率。
3. 改善系统性能：Cache 的存在使得 CPU 可以更快地执行指令和处理数据，从而缩短程序的执行时间。这对于需要处理大量数据或执行复杂计算的应用程序来说尤为重要。此外，Cache 还可以帮助减少 CPU 的空闲时间，提高 CPU 的利用率。
4. 支持并发和多任务处理：在多任务处理或并发系统中，多个程序或进程可能同时需要访问主存中的数据。通过为每个CPU或处理器核心配备独立的 Cache，可以减少它们之间对主存的竞争，提高系统的并发处理能力和响应速度。
5. 降低功耗：由于 Cache 的访问速度远快于主存，因此通过减少对主存的访问次数，可以降低系统的整体功耗。这对于移动设备、嵌入式系统等对功耗有严格要求的场景尤为重要。
6. 支持更高效的内存管理：现代操作系统和内存管理系统通常利用 Cache 的特性来优化内存访问模式，如通过**预测和预取**技术来提前将数据加载到 Cache 中，以进一步减少内存访问延迟和提高系统性能。

### 9.动态库和静态库的区别？
1. 链接方式
静态库：在编译链接过程中，静态库的内容会被完整地复制到生成的可执行文件中。
动态库：在编译链接过程中，动态库的引用会被放置到生成的可执行文件中，但动态库的实际代码并不会复制到可执行文件中。

2. 运行时行为
静态库：由于静态库的内容已经被复制到可执行文件中，因此程序在运行时对静态库没有依赖性。
动态库：程序在运行时需要动态地加载和链接动态库。如果动态库文件不存在或版本不匹配，程序可能无法正常运行。

3. 优点
静态库：1. 程序执行时不需要外部依赖，可移植性强。2. 避免了动态库可能带来的版本冲突问题。
动态库：1. 减少了可执行文件的大小，因为多个程序可以共享同一个动态库。便于更新和维护，只需更新动态库文件，无需重新编译所有依赖该库的程序。

4. 缺点：
静态库：1. 增加了可执行文件的大小，因为需要将静态库的内容完整复制。2. 如果多个程序使用同一个静态库，会造成存储资源的浪费。
动态库：1. 程序运行时需要外部依赖，如果动态库缺失或版本不匹配，程序可能无法正常运行。可能存在版本冲突问题，不同程序可能依赖不同版本的动态库。

### 10.uboot储存在哪里？
通常，uboot被储存在以下几种非易失性存储设备之一中：
* Flash存储器：
NOR Flash：NOR Flash的特点是允许芯片内执行（XIP, Execute In Place），即CPU可以直接从NOR Flash中读取指令并执行，而无需先将其复制到RAM中。这使得NOR Flash成为存放uboot的理想选择，因为uboot作为引导程序，需要在系统启动时尽快被CPU读取并执行。NOR Flash通常具有较小的存储容量，但读写速度较快。

NAND Flash：NAND Flash通常具有更大的存储容量和更低的成本，但它不支持XIP，即CPU不能直接从中执行指令。因此，在使用NAND Flash时，uboot通常需要被复制到RAM中才能执行。尽管如此，NAND Flash仍然是许多嵌入式系统中常用的存储设备，用于存放uboot和其他固件。

SD卡或MMC卡：
对于一些支持从SD卡或MMC卡启动的嵌入式系统，uboot也可以被存放在这些设备中。这种方式便于在系统开发或调试阶段更新uboot代码，同时也为系统提供了更大的灵活性和可扩展性。
其他存储设备：
在一些特殊的应用场景中，uboot还可能被存放在其他类型的非易失性存储设备中，如USB存储设备、eMMC（Embedded MultiMediaCard）等。
无论uboot被存放在哪种存储设备中，它都需要在系统的启动过程中被正确地读取和执行。这通常涉及到系统启动时的固件（如BIOS、UEFI或固件中的启动加载程序）识别并加载uboot，然后uboot再负责初始化硬件、加载操作系统内核等后续任务。

需要注意的是，uboot的储存位置并不是固定的，它可以根据具体的硬件设计和系统需求进行选择和配置。因此，在开发或调试嵌入式系统时，需要仔细考虑uboot的储存位置以及相关的启动配置。

xspi的方式把镜像烧到nor flash里面。

### 11.linux kernel分配内存时，都有哪些标志，意义分别是什么？
GFP代表Get Free Page（获取空闲页）的缩写，是内核内存分配函数中的标志位。GFP标志位用于指定内存分配的策略和要求，包括内存类型、大小、位置等。
1. GFP_ATOMIC
作用：表示原子的内存分配。它用于不允许睡眠的上下文，比如中断处理程序或持有自旋锁的代码段。使用此标志可以确保内存分配不会导致调用者睡眠，从而提高系统的响应性和稳定性。
使用场景：在中断上下文、持有自旋锁或其他不允许睡眠的地方使用。
注意事项：由于不允许睡眠，GFP_ATOMIC的内存分配成功率较低，因为它只能分配立即可用的内存。因此，在使用时需要谨慎处理内存分配失败的情况。

2. __GFP_HIGHMEM
作用：允许分配高端内存（high memory）。高端内存是指物理地址空间高于可直接映射的内存区域，需要通过分页机制来访问。
使用场景：在需要分配大量内存或用户态内存分配的场景中使用。
注意事项：使用高端内存时，必须通过特定的机制（如kmap）进行映射访问，这可能会引入额外的开销。

3. GFP_USER
作用：用于用户空间的内存分配。虽然这个标志本身在内核内存分配函数中不常见，但它体现了内存分配的一个方向——区分内核空间与用户空间的内存分配需求。
使用场景：通常不会直接在内核内存分配函数中使用GFP_USER，但在理解内存分配策略时，需要知道这种区分。

4. GFP_NOWAIT
作用：类似于GFP_ATOMIC，但更强调“不等待”的特性。它同样用于不允许睡眠的上下文，确保内存分配不会使调用者进入睡眠状态。
使用场景：在需要快速响应的场合，如中断处理、时间敏感的任务等。

5. GFP_DMA
作用：用于分配适合DMA（直接内存访问）操作的内存。这种内存通常具有特定的物理地址和访问速度要求。
使用场景：在需要进行DMA操作的设备驱动程序中使用。

6. GFP_HIGHUSER
作用：结合了GFP_USER和__GFP_HIGHMEM的特性，用于用户空间的高端内存分配。
使用场景：在需要为用户空间分配大量内存且这些内存位于高端内存区域的场合。

7. GFP_NOIO 和 GFP_NOFS
作用：这两个标志分别禁止在内存分配过程中启动磁盘IO和文件系统操作。它们用于在特定的上下文中限制内存分配可能带来的副作用。
使用场景：在需要避免IO或文件系统操作干扰的场合，如文件系统自身的恢复过程或磁盘IO压力很大的情况下。

8. GFP_KSWAPD_RECLAIM
作用：允许kswapd（内核的页面守护进程）在内存分配过程中回收内存。这通常用于平衡内存使用和提高系统性能。
使用场景：在内存分配请求可能导致系统内存压力增大的情况下使用。

### 12.进程和线程的区别
进程是操作系统进行资源分配的基本单位，线程是CPU进行运算调度的基本单位。
1. 定义与关系
进程（Process）：进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。它是程序的一次执行实例，拥有独立的内存空间、文件描述符等资源。
线程（Thread）：线程是进程的一部分，是CPU调度和分派的基本单位，是比进程更小的能够独立运行的基本单位。线程共享进程的地址空间和资源，但拥有独立的执行流程。
2. 资源占用与通信
资源占用：进程拥有独立的内存空间、文件描述符等资源，而线程则共享进程的资源。因此，线程的创建和销毁开销较小，因为它们不需要复制整个进程的资源。
通信：进程间的通信需要通过显式的机制，如管道、消息队列、共享内存等来实现，相对复杂且开销较大。而线程间的通信则更为直接和方便，因为它们可以直接读写共享的内存区域。
3. 并发与并行
并发：进程和线程都可以实现并发操作，即多个任务同时执行，但具体实现方式有所不同。进程通过操作系统的调度机制实现并发，而线程则通过共享进程的资源和执行上下文来实现更高的并发性。
并行：在多核处理器环境下，进程和线程都可以实现并行操作，即多个任务同时在不同的核心上执行。但由于线程间的切换开销较小，且共享进程的资源，因此线程在实现并行操作方面通常具有更高的效率。
4. 管理与调度
管理：进程的管理相对复杂，因为每个进程都拥有独立的资源。而线程的管理则更为灵活和简单，因为它们共享进程的资源。
调度：进程是系统进行资源分配和调度的基本单位，而线程则是CPU调度和分派的基本单位。因此，线程的切换开销较小，能够更快地响应系统的调度请求。
5. 安全性与稳定性
安全性：由于进程间的地址空间隔离，不同进程的数据互不影响，因此进程间的通信虽然开销较大，但更加安全可靠。而线程间的通信虽然方便，但由于共享进程的资源，因此需要考虑共享数据的安全性和避免竞争条件。
稳定性：一个进程的崩溃通常不会影响其他进程，但一个线程的崩溃可能会影响到整个程序的稳定性，因为它可能破坏了进程中的共享资源。

### 13.解释下什么叫死锁，怎么语法死锁？
定义：
死锁是指两个或两个以上的进程（或线程）在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞现象，若无外力作用，它们都将无法继续执行下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程（或线程）称为死锁进程（或线程）。在编程、计算机资源调度等领域，死锁是一个常见且复杂的问题，尤其在操作系统和数据库管理中更为显著。

必要条件：
1. 互斥条件：进程对所需系统资源的互斥使用，即任一资源一次只能被一个进程使用。
2. 占有和等待条件：进程持有部分资源，同时等待获取其他进程占有的资源。
3. 不可抢占条件：进程占有的资源不能被其他进程抢占，只有进程主动释放。
4. 循环等待条件：存在一个进程资源申请的循环链，每个进程都在等待下一个进程释放资源，最后一个进程又在等待第一个进程释放资源。

预防死锁的方法：
1. 资源一次性分配
如果系统当前存在的资源数量能够满足进程的资源需求，便一次性地为进程分配其所需的全部资源。在该进程完成之后再一次性地回收全部资源。这种方法可以确保进程在执行过程中不会因为资源不足而等待其他进程释放资源，从而避免死锁。
2. 剥夺资源：
当系统中某些进程在已经占有一定数量资源的情况下，又提出新的资源请求，而操作系统不能立即满足该进程的需求时，该进程必须立即释放已经占有和保持的所有资源，待以后需要时再重新申请。
3. 资源有序分配法：
对所有可提供的资源按类型排序编号，所有进程对资源的请求也必须严格按序号递增的次序提出。这样可以避免产生资源占有和资源需求的回路出现，从而防止死锁的产生。此方法也被称为摒弃“环路等待”条件。
4. 使用锁机制：
在多线程编程中，可以通过锁机制来控制对共享资源的访问。例如，统一加锁顺序，确保多个线程在访问多个资源时总是以相同的顺序申请锁；尽快释放锁，减少其他线程等待锁的时间；使用无锁数据结构或可重入锁、公平锁等高级锁机制来降低死锁的风险。
5. 设置锁超时和重试机制：
在获取锁的过程中设置超时时间，如果线程在超时时间内仍未获得锁，则放弃该次锁的申请，并可能执行其他操作或重试。这可以防止线程无限期地等待一个锁，从而避免死锁。

### 14.semaphore的源码逻辑？
init阶段：根据用户设置值进行初始化，对semphore进行赋值。
里面其实使用了spinlock做临界资源保护。
down阶段：如果semphore值大于0，则直接减1；否则将当前进程设置为UNINTERUPTED状态，并添加到等待链表中。
up阶段：如果等待链表不为空，则将第一个进程设置为RUNNING状态，并从等待链表中删除。如果等待链表为空，则直接将semphore值加1。
如果共享资源比较复杂，且允许进程休眠的场景，可以使用信号量semaphore。
特点：
1. 用于进程和进程间的同步
2. 允许多个进程同时访问共享资源
3. 进程获取不到临界资源时，会进入休眠状态，并让出cpu
4. 被信号量包含的临界区代码允许睡眠
5. 本质是基于调度器的，UP和SMP实现无差别（UP: Uni-Processor, smp: Symmetric Multi-Processing）
6. 不支持进程和中断间的同步，原因是中断和进程是不同的执行上下文，不能共享资源


### 15.linux原子操作的源码逻辑？
在linux中，原子操作通常使用atomic_t类型来表示。atomic_t是一个结构体，其中包含一个int类型的值。原子操作涉及对整型变量的读取和修改，而原子操作可以保证这些操作是原子的，即不可分割的。
具体底层通过汇编指令实现，在ARM64架构中，使用ldxr和stxr指令来实现原子操作。ldxr指令用于读取内存中的值，stxr指令用于将新值写入到内存中。如果stxr返回成功，则表示原子操作成功完成；否则，需要重新尝试。
ldxr指令和stxr指令都是原子操作，因此可以使用它们来实现原子操作。在实现原子操作时，需要保证对变量的读取和修改是原子的，即不可分割的。

### 16.自旋锁的特点
1. spinlock是一种**死等**的锁机制，底层通过汇编代码实现。
2. semaphore可以允许多个执行单元进入临界区，spin_lock不行，一次只能有一个执行单元获取锁并进入临界区，其他的执行单元都是在门口不断的死等。
3. 使用spinlock保护的临界区代码要求执行时间短。由于spin_lock死等这种特性，如果临界区执行时间太长，那么不断在临界区门口“死等”的那些执行单元会过多的耗费CPU。
4. spinlock可以在中断上下文执行。由于不睡眠，因此spinlock可以在中断上下文中使用。
5. 临界区代码不能睡眠，也不能调用那些可能引起睡眠的函数。
相关api：
```C
void spin_lock (spinlock_t* lock);
//进程和进程之间的同步

void spin_lock_bh(spinlock_t *lock);
//涉及到和本地软中断之间的同步

void spin_lock_irq(spinlock_t *lock);
//涉及到和本地硬件中断之间的同步

void spin_lock_irgsave(lock, flags);
//涉及到和本地硬件中断之间的同步并保存本地中断状态

int spin_trylock(spinlock_t *lock);
//尝试获取锁，如果成功返回非零值，否则返回零值
```
源码分析：
spinlock_t的底层是通过arch_spinlock_t实现的，而spinlock_t是一个结构体。
```C
typedef struct {
    union {
        u32 slock;
        struct __raw_tickets {
        #ifdef __ARMEB__   //大端模式
            u16 next;
            u16 owner;
        #else
            u16 owner；
            u16 next;
        #endif
        } tickets;
    };
} arch_spinlock_t;
```
1.刚开始owner=next=0
2.第一个thread获取spinlock，可获取成功，此时owner=0, next=0;
3.第二个thread获取spinlock,如果第一个thread 还没有释放spinlock，则next++, next变为1;
4.第三个thread获取spinlock,如果第一个thread 还没有释放spinlock，则next++, next变为2;
5.此时第一个thread释放spinlock，则执行owner++, owner=1;
6.虽然此时第二个thread和第三个thread都在等待spinlock,但是因为第二个thread的next=owner,所以第二个thread可以获取到spinlock，第三个thread则继续等待。
这样保证了spinlock的**唤醒机制是先到先唤醒**，后到后唤醒保证了公平性。

### 17.读写自旋锁
加锁逻辑：
(1) 假设临界区内没有任何的thread，这时候任何read thread或者write thread可以进入
(2) 假设有read thread在临界区内，这时候任何read thread都可以进入，但是write thread不能进入
(3) 假设临界区内有一个write thread，这时候任何的read thread或者write thread都不可以进入;
(4) 假设临界区内有一个或者多个read thread，write thread当然不可以进入临界区，但是该write thread也无法阻止后续read thread的进入，他要一直等到临界区一个read thread也没有的时候，才可以进入。
可见，rw_spinlock 给reader赋予了更高的优先级。

### 18.为什么有RCU机制
随着计算机硬件技术的发展，CPU相对于存储器件的运算速度优势越来越大。
在这种背景下，获取基于counter (**需要访问存储器件**)的锁 (例如spin lock，rwlock)的机制开销越来越明显。
因此，那些基于一multi-processor之间的共享的counter的锁机制已经不能满足性能的需求，在这种情况下，RCU机制应运而生。
原理：
RCU（Read-Copy-Update）是一种用于并发编程的技术，旨在提供高效且无锁的读操作，同时保证数据一致性和并发性。
其基本原理是，在需要修改共享数据时，RCU采用“写时复制”（copy-on-write）的策略。初始阶段，所有读取线程可以同时访问共享数据。当需要更新数据时，RCU会创建一个新的数据副本，并将修改应用于该副本，而不是直接修改原始数据。这样，在更新期间，读取线程仍然可以访问旧版本的数据，从而避免了读写冲突和锁的需求。当所有线程都不访问时，RCU会更新原始数据。

优点：
1. 读者侧开销少：读取操作不需要获取任何锁，也不需要执行原子指令或内存屏障，从而降低了读者线程的开销。
2. 避免死锁和优先级反转：由于不使用传统的锁机制，RCU避免了死锁和优先级反转的问题。
3. 良好的实时延迟：由于读操作不需要等待写操作完成，RCU能够提供更好的实时性能。
4. 内存安全：RCU避免了内存泄露的危险，因为旧的数据副本会在确认所有读者都不再使用后才会被释放。

### 19.简述slab分配器的基本思想
slab 分配器的基本思想是，先利用页面分配器分配出单个或者一组连续的物理页面，然后在此基础上将整块页面分割成多个相等的小内存单元，以满足小内存空间分配的需要。

Slab分配器通过管理一组称为“Slab”的内存块来减少内存碎片并加快分配和释放的速度。
在这个过程中，涉及到几个关键的数据结构，包括kmem_cache、slab和obj（通常指的是由Slab管理的单个对象）。
下面简述这些结构体之间的联系与关系：
**kmem_cache**
定义：kmem_cache是Slab分配器的核心结构体，用于表示一个缓存。每个kmem_cache代表了一种特定大小的对象集合，这些对象由该缓存统一管理和分配。
关联：kmem_cache包含了多个slab结构体的指针（通常以链表或数组形式组织），每个slab都是这种对象大小的一个内存块集合。
其中维护了多个链表:
slabs_partial: 将 kmem_cache 中所有的半空闲的 slab 加入到该链表中。
slabs_full：将 kmem_cache 中所有已经满员的 slab 加入到该链表中。
slabs_free: 将 kmem_cache 中所有完全空闲的 slab 加入到该链表中

slab
定义：slab是实际分配给用户内存请求的内存块。一个slab可能包含多个对象（obj），这些对象的大小由所属的kmem_cache决定。
功能：slab的主要功能是存储和管理一定数量的大小相同的对象。这些对象在分配时从Slab中取出，在释放时放回Slab。
关联：slab属于某个特定的kmem_cache，且其内部的对象大小由该kmem_cache决定。同时，slab内部会维护一些元数据，如空闲对象的数量、空闲对象的链表等，以便高效管理。
obj（对象）
定义：obj不是直接作为一个结构体存在的，而是指由slab管理的单个内存块（即对象）。这些对象的大小由它们所属的kmem_cache定义。
功能：用户从kmem_cache中分配得到的内存就是这些obj中的一个。这些对象在被分配时会被初始化（如果需要），并在被释放时可能会被清除（或仅仅是被标记为空闲）。
关联：obj与slab直接相关，它们是slab内存块中的实际使用部分。每个obj的起始地址和大小由所属的slab和kmem_cache共同决定。
总结
kmem_cache、slab和obj之间的关系可以总结为：kmem_cache是管理特定大小对象集合的缓存，它包含了多个slab；每个slab是实际存储和管理这些对象的内存块，内部包含多个obj；而obj则是用户最终分配和使用的内存单元。这种结构有效地组织和管理了小块内存的分配和释放，提高了内存使用的效率和性能。

Slab机制中的着色原理：
通过在计算对象在内存中的起始位置时引入特定的偏移量，来避免或减少多个对象映射到同一缓存行（Cache Line）上造成的缓存冲突。这种偏移量的计算确保了对象在物理内存中的分布更加分散，从而提高了缓存的利用率和命中率。

精炼来说，着色原理就是“分散存储，减少冲突”，它通过在对象分配时巧妙地“上色”（即计算偏移量），使得缓存的使用更加高效，进而提升了系统的性能。

### 20.说下kmalloc的底层实现？
kmalloc 是 Linux 内核中用于分配小块连续物理内存的函数，它是内核中最常用的内存分配方式之一。
kmalloc 的实现涉及到内核的多个组件和层次，从底层的数据结构到高层的分配策略都有涉及。
从源码的层次来分析 kmalloc 的实现：
1. kmalloc 的声明
首先，kmalloc 的声明位于 include/linux/slab.h 文件中。这个文件包含了 kmalloc、kfree 等内存分配和释放函数的声明，以及相关的宏定义和类型定义。
```c
void *kmalloc(size_t size, gfp_t flags);
```
其中，size 是需要分配的内存大小，flags 是分配标志，用于指定分配行为（如是否允许睡眠等）。

2. kmalloc 的实现
kmalloc 的实现通常不会直接出现在 include/linux/slab.h 中，而是由内核的其他部分提供。
在较新的 Linux 内核中，kmalloc 的实现通常与 kmem_cache_alloc 紧密相关，因为 kmalloc 实际上是通过一组 kmem_cache 缓存来管理小块内存的分配的。
kmalloc 的核心实现位于 mm/slab.c 文件中，但直接调用 kmalloc 时，它通常会通过一系列的宏和函数跳转，最终到达 kmem_cache_alloc。

3. kmem_cache 缓存
kmem_cache 是 Linux 内核中的一种高速缓存机制，用于管理小块内存的分配和释放。每个 kmem_cache 缓存都对应于一种特定大小的对象，并且会预先分配一定数量的内存页来存储这些对象。
当 kmalloc 被调用时，它首先会根据请求的大小和标志选择一个合适的 kmem_cache 缓存。这个选择过程可能涉及到查找一个最接近请求大小的缓存，或者在某些情况下，可能会使用一个通用的缓存。

4. 分配内存
一旦选择了合适的 kmem_cache 缓存，kmalloc 就会调用 kmem_cache_alloc 函数来从这个缓存中分配一个对象。kmem_cache_alloc 会检查缓存中的空闲对象列表，如果列表不为空，则直接从列表中取出一个对象并返回；如果列表为空，则可能需要从伙伴系统（Buddy System）中分配新的内存页来扩展缓存。

5. 回收内存
当使用 kfree 释放内存时，释放的对象会被放回其对应的 kmem_cache 缓存中的空闲对象列表，以便后续分配重用。

6. 总结
从源码的层次来看，kmalloc 的实现涉及到了多个组件和层次：
声明：在 include/linux/slab.h 中声明。
核心实现：通过 kmem_cache_alloc 等函数在 mm/slab.c 等文件中实现。
缓存机制：kmem_cache 缓存用于管理小块内存的分配和释放。
伙伴系统：在需要时，通过伙伴系统来分配新的内存页。
这种设计使得 kmalloc 能够高效地处理小块内存的分配和释放，同时减少了内存碎片的产生，提高了内存使用的效率。

### 21.说下vmalloc的底层实现？
vmalloc 是 Linux 内核中用于分配大块虚拟连续内存的函数，但它分配的内存块在物理内存中可能不是连续的。
vmalloc 的实现涉及到内核内存管理的多个层次，包括虚拟内存管理、物理内存管理以及页面映射等。
从源码的层次来分析 vmalloc 的底层实现:
1. vmalloc 的声明
vmalloc 的声明通常位于 include/linux/vmalloc.h 或其他相关的头文件中。它的原型如下：
```c
void *vmalloc(unsigned long size);
```
2. vmalloc 的实现
vmalloc 的实现通常位于 mm/vmalloc.c 文件中。不过，需要注意的是，vmalloc 可能会通过一系列的宏和函数跳转，最终到达实际的内存分配逻辑。

在 vmalloc 的实现中，主要会调用 __vmalloc_node_flags 函数（或其简化版本，如 __vmalloc_node），这个函数提供了更多的控制选项，包括 NUMA 节点和分配标志。

3. __vmalloc_node_flags 的实现
__vmalloc_node_flags 是 vmalloc 分配逻辑的核心。
它首先会计算需要分配的页面数（基于请求的大小和页面大小），然后调用底层的内存分配函数来分配这些页面。

在分配页面时，__vmalloc_node_flags 可能会使用 alloc_pages_vma 或类似的函数，这些函数最终会调用**伙伴系统**（Buddy System）或类似机制来分配物理页面。然而，与 __get_free_pages 不同的是，vmalloc 不保证这些页面在物理上是连续的。

4. 虚拟地址映射
分配到物理页面后，__vmalloc_node_flags 接下来需要将这些物理页面映射到虚拟地址空间中。
这是通过调用 vmalloc_area_node（或类似函数）来完成的，该函数会创建一个 vm_struct 结构体来表示这个虚拟内存区域，并将其加入到内核的虚拟内存映射表中。
vm_struct 结构体包含了虚拟内存区域的起始地址、大小、物理页面列表以及其他相关信息。通过这个结构体，内核可以管理虚拟内存到物理内存的映射。

5. 分配结果
一旦虚拟地址映射完成，__vmalloc_node_flags 就会返回指向分配的内存块的虚拟地址。这个地址在虚拟地址空间中是连续的，但对应的物理页面可能不是连续的。

6. 释放内存
当使用完 vmalloc 分配的内存后，应该使用 vfree 函数来释放它。vfree 会查找对应的 vm_struct 结构体，并撤销虚拟地址映射，然后释放相关的物理页面。

### 22. 简述LINUX驱动中字符设备和块设备的区别?
1. 块设备只能以块为单位接收输入和返回输出，而字符设备则以字节为单位。
2. 块设备对于IO请求有对应的缓冲区，因此可以选择以什么顺序进行响应(并不是先请求先响应)，字符设备无需缓冲，被直接读写。
3. 字符设备只能被顺序读写，而块设备可以随机访问。

### 23.说明下softirq有哪些实现类型，及为什么要有这么多类型？
通过源码可以查看具体的有哪些软中断类型：
```C
const char * const softirq_to_name[NR_SOFTIRQS] = {
	"HI", "TIMER", "NET_TX", "NET_RX", "BLOCK", "IRQ_POLL",
	"TASKLET", "SCHED", "HRTIMER", "RCU"
};
```
1. HI：用于高优先级的tasklet。Tasklet是一种基于软中断实现的机制，用于执行轻量级、可延迟的任务。高优先级tasklet需要尽快得到处理。
2. TIMER：用于处理软件定时器事件。这些定时器通常是基于系统tick的，用于执行周期性的任务或延迟任务。
3. NET_TX和 NET_RX：用于发送和接收网络数据包。网络数据的处理通常需要较高的优先级，以确保网络通信的实时性和效率。
4. BLOCK：用于块设备的I/O操作。块设备（如硬盘）的I/O操作通常涉及大量的数据传输和复杂的处理逻辑，使用软中断可以提高处理效率。
5. IRQ_POLL：用于轮询方式的IRQ处理。在某些情况下，当硬件不支持中断时，可以通过轮询方式模拟中断处理。
6. TASKLET：用于普通的tasklet，即低优先级的tasklet。这些tasklet通常处理不那么紧急的任务。
7. SCHED：与内核调度器相关，用于多CPU之间的负载均衡等任务。
8. HRTIMER：用于高精度定时器的处理。高精度定时器需要更高的时间精度和更低的延迟。
9. RCU：用于处理RCU（Read-Copy Update）相关的任务。RCU是一种同步机制，用于减少数据读取时的锁竞争。

定义多种类型的软中断，主要是出于以下考虑：
优先级管理：不同类型的软中断具有不同的优先级。
任务分类：将不同类型的任务分配给不同的软中断类型，有助于实现任务的分类管理。
并发执行：软中断可以在多个CPU上并发执行，这有助于提高系统的并行处理能力。通过为不同类型的任务分配不同的软中断类型，内核可以更好地利用多核处理器的优势，提高系统的整体吞吐率。
灵活性和可扩展性：定义多种类型的软中断使得内核在设计和实现时更加灵活和可扩展。随着系统需求的不断变化和新技术的发展，内核可以通过添加新的软中断类型来支持新的功能和服务。

## 24.说明下spinlock的API都有哪些，分别在哪些场景使用？
1. 基本的加锁和解锁
```C
加锁：void spin_lock(spinlock_t *lock);
解锁：void spin_unlock(spinlock_t *lock);
```

2. 当需要在加锁的同时**防止硬件中断**发生时，可以使用以下API：
```c
void spin_lock_irq(spinlock_t *lock);
void spin_unlock_irq(spinlock_t *lock);
```
3. 加锁并保存中断状态：
```C
void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
```
主要用于保护那些不能被硬件中断打断的临界区代码。
如果你在中断服务例程（ISR）中需要执行一段临界区代码，而这段代码又可能与其他中断或代码段产生冲突，那么可以使用 spin_lock_irq 来保护这段代码。

4. 当需要在加锁的同时防止软中断（softirq、tasklet等）发生时，可以使用：
```C
加锁并屏蔽软中断：void spin_lock_bh(spinlock_t *lock);
解锁并恢复软中断：void spin_unlock_bh(spinlock_t *lock);
```
这个函数在获取自旋锁的同时会禁用软中断，以防止在持有锁期间执行这些类型的底半处理函数。